{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML FOR IMBALANCED CLASSIFICATION\n",
    "\n",
    "**CONTENTS**\n",
    "\n",
    "- [Example Dataset](#example)\n",
    "- [Methods for Imbalanced Classification](#methods)\n",
    "    + [Improve The Dataset](#dataset)\n",
    "        + [Up-sampling The Minority Class](#up_sampling)\n",
    "        + [Down-sampling The Majority Class](#down_sampling)\n",
    "    + [Changing The Performance Metric ](#metrics)\n",
    "    + [Use Specific Models for Imbalanced Classification](#model)\n",
    "        + [Penalizing Algorithms (Cost_sensitive Training](#penalizing)\n",
    "        + [Tree-Based Algorithms](#tree-base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Good reference for handling imbalanced classification](https://elitedatascience.com/imbalanced-classes)\n",
    "- [Ref2](https://www.svds.com/learning-imbalanced-classes/)\n",
    "- Examples of imbalanced classes:\n",
    "    + Fraud detection\n",
    "    + Spam filtering\n",
    "    + Disease screening\n",
    "    + SaaS subscription churn\n",
    "    + Advertising click-throughs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example'></a>\n",
    "## 1. EXAMPLE DATASET OF IMBALANCED CLASSIFICATION\n",
    "\n",
    "### 1.1. DATASET DESCRIPTION\n",
    "\n",
    "- [Balance Scale Weight & Distance Database](http://archive.ics.uci.edu/ml/datasets/balance+scale)\n",
    "- Number of Attributes: 4 (numeric) + class name = 5\n",
    "- Attribute Information:\n",
    "\t1. Class Name: 3 (L, B, R)\n",
    "\t2. Left-Weight: 5 (1, 2, 3, 4, 5)\n",
    "\t3. Left-Distance: 5 (1, 2, 3, 4, 5)\n",
    "\t4. Right-Weight: 5 (1, 2, 3, 4, 5)\n",
    "\t5. Right-Distance: 5 (1, 2, 3, 4, 5)\n",
    "- Number of Instances: 625 (49 balanced, 288 left, 288 right)\n",
    "- Class Distribution: \n",
    "   1. 46.08 percent are L\n",
    "   2. 07.84 percent are B\n",
    "   3. 46.08 percent are R\n",
    "   \n",
    "   \n",
    "**=> In this study, the dataset will be converted into a binary classification problem: balanced and non-balanced class.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. PROCESS THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  x1  x2  x3  x4\n",
       "0     B   1   1   1   1\n",
       "1     R   1   1   1   2\n",
       "2     R   1   1   1   3"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/balance-scale.data\", header = None, \\\n",
    "                   names = ['class', 'x1', 'x2', 'x3', 'x4'])\n",
    "print(data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    288\n",
       "L    288\n",
       "B     49\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4  balance\n",
       "0   1   1   1   1        1\n",
       "1   1   1   1   2        0\n",
       "2   1   1   1   3        0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Convert the 3-classes into binary class\n",
    "data['balance'] = [1 if b == 'B' else 0 for b in data['class']]\n",
    "data.drop(['class'], axis = 1, inplace = True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    576\n",
       "1     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.balance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. BRIEFLY TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# sklearn metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def fitModels(X, y):\n",
    "    \"\"\" Create and train the data using different ML models\n",
    "    Print out all the accuracy, recall, precision and f1 score of each model\n",
    "    Return a list of model for plotting\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    #### Prepare the dataset\n",
    "    ### Use option stratify for imbalanced class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "    #### Naive Bayes\n",
    "    model_name = \"Naive Bayes\"\n",
    "    clf = GaussianNB()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    models.append([model_name, clf])\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                                accuracy))\n",
    "    print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "    \n",
    "    #### support vector machine\n",
    "    model_name = \"Support Vector Machine\"\n",
    "    clf = svm.SVC(kernel = \"linear\", gamma = \"auto\")\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    models.append([model_name, clf])\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                                accuracy))\n",
    "    print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "    \n",
    "    #### k-nearest neighbor\n",
    "    model_name = \"K-nearest Neighbor\"\n",
    "    clf = KNeighborsClassifier(n_neighbors = 2)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    models.append([model_name, clf])\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                                accuracy))\n",
    "    print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "    \n",
    "    #### LogisticRegression\n",
    "    model_name = \"Logistic Regression\"\n",
    "    clf = LogisticRegression()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    models.append([model_name, clf])\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                                accuracy))\n",
    "    print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "    \n",
    "    \n",
    "    #### Decision tree\n",
    "    model_name = \"Decision Tree\"\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    models.append([model_name, clf])\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                                accuracy))\n",
    "    print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "    \n",
    "    #### Random forest\n",
    "    model_name = \"Random Forest\"\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators = 100)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    models.append([model_name, clf])\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                                accuracy))\n",
    "    print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "    \n",
    "    #### AdaBoost\n",
    "    model_name = \"AdaBoost\"\n",
    "    clf = ensemble.AdaBoostClassifier(n_estimators = 100)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    models.append([model_name, clf])\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                                accuracy))\n",
    "    print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "    \n",
    "    #### GradientBoost\n",
    "    model_name = \"Gradient Boosting\"\n",
    "    clf = ensemble.GradientBoostingClassifier(n_estimators = 100)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    models.append([model_name, clf])\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                                accuracy))\n",
    "    print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Accuracy score: 0.92\n",
      "Recall: 0.0, Precision: 0.0, F1 score: 0.0\n",
      "\n",
      "Support Vector Machine - Accuracy score: 0.92\n",
      "Recall: 0.0, Precision: 0.0, F1 score: 0.0\n",
      "\n",
      "K-nearest Neighbor - Accuracy score: 0.904\n",
      "Recall: 0.0, Precision: 0.0, F1 score: 0.0\n",
      "\n",
      "Logistic Regression - Accuracy score: 0.92\n",
      "Recall: 0.0, Precision: 0.0, F1 score: 0.0\n",
      "\n",
      "Decision Tree - Accuracy score: 0.84\n",
      "Recall: 0.0, Precision: 0.0, F1 score: 0.0\n",
      "\n",
      "Random Forest - Accuracy score: 0.912\n",
      "Recall: 0.0, Precision: 0.0, F1 score: 0.0\n",
      "\n",
      "AdaBoost - Accuracy score: 0.92\n",
      "Recall: 0.0, Precision: 0.0, F1 score: 0.0\n",
      "\n",
      "Gradient Boosting - Accuracy score: 0.896\n",
      "Recall: 0.0, Precision: 0.0, F1 score: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data['balance'])\n",
    "models = fitModels(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Could not predict the minor class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='methods'></a>\n",
    "## 2. METHODS FOR IMBALANCED CLASSIFICATION\n",
    "\n",
    "<a id='dataset'></a>\n",
    "### 2.1. IMPROVE THE DATASET\n",
    "\n",
    "- Some methods to improve the dataset (make imbalanced classification more balanced):\n",
    "    + For minority class:\n",
    "        + Up-sampling the minority class\n",
    "        + Combine minority classes (for multi-class problem):\n",
    "            + Example: predict credit card fraud: There are different fraud class => combine all together.\n",
    "        + Data Augmentation: create synthetic samples.\n",
    "    + For majority class: Down-sampling\n",
    "- Below is the techniques for up-sampling and down-sampling\n",
    "\n",
    "<a id='up_sampling'></a>\n",
    "#### 2.1.1. UP-SAMPLING THE MINORITY CLASS\n",
    "\n",
    "- Randomly duplicating observations from the minority class to reinforce its signal.\n",
    "- Simple and most common method: resample the minority class with replacement using `resample` from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: (576, 5), Minority class: (49, 5)\n",
      "Minority class - upsampled.shape (576, 5)\n",
      "Count target y in each class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    576\n",
       "0    576\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "data_major = data.query('balance == 0')\n",
    "data_minor = data.query('balance == 1')\n",
    "print(\"Majority class: {}, Minority class: {}\".format(data_major.shape, data_minor.shape))\n",
    "### Up-sampling the minority class\n",
    "data_minor_upsampled = resample(data_minor, replace = True, \n",
    "                                n_samples = data_major.shape[0], random_state = 42)\n",
    "print(\"Minority class - upsampled.shape\", data_minor_upsampled.shape)\n",
    "# combine the class\n",
    "data_upsampled = pd.concat([data_major, data_minor_upsampled])\n",
    "print('Count target y in each class:')\n",
    "data_upsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Accuracy score: 0.5064935064935064\n",
      "Recall: 0.5043478260869565, Precision: 0.5043478260869565, F1 score: 0.5043478260869565\n",
      "\n",
      "Support Vector Machine - Accuracy score: 0.5194805194805194\n",
      "Recall: 0.5826086956521739, Precision: 0.5153846153846153, F1 score: 0.5469387755102041\n",
      "\n",
      "K-nearest Neighbor - Accuracy score: 0.9567099567099567\n",
      "Recall: 1.0, Precision: 0.92, F1 score: 0.9583333333333334\n",
      "\n",
      "Logistic Regression - Accuracy score: 0.4935064935064935\n",
      "Recall: 0.4782608695652174, Precision: 0.49107142857142855, F1 score: 0.4845814977973568\n",
      "\n",
      "Decision Tree - Accuracy score: 0.9567099567099567\n",
      "Recall: 1.0, Precision: 0.92, F1 score: 0.9583333333333334\n",
      "\n",
      "Random Forest - Accuracy score: 0.974025974025974\n",
      "Recall: 1.0, Precision: 0.9504132231404959, F1 score: 0.9745762711864406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - Accuracy score: 0.5324675324675324\n",
      "Recall: 0.5826086956521739, Precision: 0.5275590551181102, F1 score: 0.5537190082644627\n",
      "\n",
      "Gradient Boosting - Accuracy score: 0.8874458874458875\n",
      "Recall: 0.9739130434782609, Precision: 0.8296296296296296, F1 score: 0.896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data_upsampled[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data_upsampled['balance'])\n",
    "models = fitModels(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy: 0.96\n",
      "Recall: 1.0\n",
      "Precision: 0.6666666666666666\n",
      "F1 score: 0.8\n",
      "y_test [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_pred [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#### Choose random forest model as the best performance model => Predict the real y_test\n",
    "X = np.array(data[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data['balance'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 42, stratify = y)\n",
    "\n",
    "print(models[5][0])\n",
    "# Evaluate the model\n",
    "y_pred = models[5][1].predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}\\nRecall: {}\\nPrecision: {}\\nF1 score: {}\".format(accuracy, recall, precision, f1))\n",
    "\n",
    "print(\"y_test\", y_test)\n",
    "print(\"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='down_sampling'></a>\n",
    "#### 2.1.2. DOWN-SAMPLING THE MINORITY CLASS\n",
    "\n",
    "- Simple and most common method: resample the majority class without replacement using `resample` from `sklearn`.\n",
    "- Down-sampling will reduce significantly the number of observations => Could lead to underfitting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: (576, 5), Minority class: (49, 5)\n",
      "Majority class, downsampled.shape (49, 5)\n",
      "Count target y in each class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    49\n",
       "0    49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "data_major = data.query('balance == 0')\n",
    "data_minor = data.query('balance == 1')\n",
    "print(\"Majority class: {}, Minority class: {}\".format(data_major.shape, data_minor.shape))\n",
    "### Down-sampling the majority class\n",
    "data_major_downsampled = resample(data_major, replace = False, \n",
    "                                n_samples = data_minor.shape[0], random_state = 42)\n",
    "print(\"Majority class, downsampled.shape\", data_major_downsampled.shape)\n",
    "# combine the class\n",
    "data_downsampled = pd.concat([data_minor, data_major_downsampled])\n",
    "print('Count target y in each class:')\n",
    "data_downsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Accuracy score: 0.35\n",
      "Recall: 0.3, Precision: 0.3333333333333333, F1 score: 0.3157894736842105\n",
      "\n",
      "Support Vector Machine - Accuracy score: 0.25\n",
      "Recall: 0.2, Precision: 0.2222222222222222, F1 score: 0.2105263157894737\n",
      "\n",
      "K-nearest Neighbor - Accuracy score: 0.55\n",
      "Recall: 0.3, Precision: 0.6, F1 score: 0.4\n",
      "\n",
      "Logistic Regression - Accuracy score: 0.25\n",
      "Recall: 0.2, Precision: 0.2222222222222222, F1 score: 0.2105263157894737\n",
      "\n",
      "Decision Tree - Accuracy score: 0.5\n",
      "Recall: 0.4, Precision: 0.5, F1 score: 0.4444444444444445\n",
      "\n",
      "Random Forest - Accuracy score: 0.4\n",
      "Recall: 0.4, Precision: 0.4, F1 score: 0.4000000000000001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data_analysis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - Accuracy score: 0.4\n",
      "Recall: 0.5, Precision: 0.4166666666666667, F1 score: 0.45454545454545453\n",
      "\n",
      "Gradient Boosting - Accuracy score: 0.5\n",
      "Recall: 0.5, Precision: 0.5, F1 score: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data_downsampled[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data_downsampled['balance'])\n",
    "models = fitModels(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy: 0.616\n",
      "Recall: 0.7\n",
      "Precision: 0.1346153846153846\n",
      "F1 score: 0.22580645161290322\n",
      "y_test [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_pred [0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0\n",
      " 1 1 0 0 1 1 0 1 1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "#### Choose random forest model as the best performance model => Predict the real y_test\n",
    "X = np.array(data[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data['balance'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 42, stratify = y)\n",
    "\n",
    "print(models[5][0])\n",
    "# Evaluate the model\n",
    "y_pred = models[5][1].predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}\\nRecall: {}\\nPrecision: {}\\nF1 score: {}\".format(accuracy, recall, precision, f1))\n",
    "\n",
    "print(\"y_test\", y_test)\n",
    "print(\"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "### 2.2. CHANGING THE PERFORMANCE METRICS\n",
    "\n",
    "- Using AUROC value - Mostly use for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy score: 0.5151515151515151\n",
      "Recall: 0.6605504587155964, Precision: 0.4897959183673469, F1 score: 0.5624999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Using logistic regression to have the predict_proba value \n",
    "### Train on the upsampled data\n",
    "\n",
    "X = np.array(data_upsampled[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data_upsampled['balance'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#### LogisticRegression\n",
    "model_name = \"Logistic Regression\"\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                            accuracy))\n",
    "print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC val on train data 0.5445905536322387\n",
      "AUROC val on test data 0.5156414498420815\n"
     ]
    }
   ],
   "source": [
    "### Calculate the AUROC score. Need to have the attribute clf.predict_proba() \n",
    "# predict probability for each class\n",
    "from sklearn.metrics import roc_auc_score\n",
    "### keeo only the positive class (class 1 - minority class in binary classification) which is [1])\n",
    "prob_y_train_pred = clf.predict_proba(X_train)[:, 1] \n",
    "prob_y_test_pred = clf.predict_proba(X_test)[:, 1]\n",
    "print(\"AUROC val on train data\", roc_auc_score(y_train,prob_y_train_pred )) \n",
    "print(\"AUROC val on test data\", roc_auc_score(y_test, prob_y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "### 2.3. USE SPECIFIC MODELS FOR IMBALANCED CLASSIFICATION\n",
    "- Some models works well for imbalanced classification:\n",
    "    + SVC with penalizing\n",
    "    + Decision Trees algorithms\n",
    "- We can also change the problem to Anomaly Detection/Outlier Detection (clustering, k-nearest neigbor, ect.) \n",
    "\n",
    "<a id='penalizing'></a>\n",
    "#### 2.3.1. PENALIZING ALGORITHMS (COST-SENSITIVE TRAINING)\n",
    "  \n",
    "- Penalize learning algorithms that increase the cost of classification mistakes on the minority class.\n",
    "- Common technique: Penalized-SVM:\n",
    "    + SVC using `class_weight = \"balanced\"` => penalize mistakes\n",
    "    + Set `probability = True` for calculation AUROC score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalized SVM - Accuracy score: 0.48\n",
      "Recall: 0.2, Precision: 0.03389830508474576, F1 score: 0.05797101449275363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Using SVC \n",
    "### Train on the unbalanced dataset\n",
    "\n",
    "X = np.array(data[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data['balance'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "#### SVC\n",
    "from sklearn.svm import SVC\n",
    "model_name = \"Penalized SVM\"\n",
    "clf_svc = SVC(kernel = 'linear',\n",
    "             class_weight = 'balanced',\n",
    "             probability = True)\n",
    "clf_svc  = clf_svc .fit(X_train, y_train)\n",
    "# Evaluate the model\n",
    "y_pred = clf_svc .predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                            accuracy))\n",
    "print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC val on train data 0.47099393737137774\n",
      "AUROC val on test data 0.6765217391304348\n"
     ]
    }
   ],
   "source": [
    "prob_y_train_pred = clf_svc.predict_proba(X_train)[:, 1] \n",
    "prob_y_test_pred = clf_svc.predict_proba(X_test)[:, 1]\n",
    "print(\"AUROC val on train data\", roc_auc_score(y_train,prob_y_train_pred )) \n",
    "print(\"AUROC val on test data\", roc_auc_score(y_test, prob_y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tree-base'></a>\n",
    "#### 2.3.2. TREE-BASED ALGORITHMS \n",
    "- Decision trees often work well on imbalanced datasets: Their hierarchical structure allows them to learn signals from both classes.\n",
    "=> As you can see in **Part 2.1**, random forest algorithm works best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy score: 0.96\n",
      "Recall: 1.0, Precision: 0.6666666666666666, F1 score: 0.8\n",
      "\n",
      "AUROC val on train data 0.9999999999999999\n",
      "AUROC val on test data 1.0\n"
     ]
    }
   ],
   "source": [
    "#### Using RandomForest\n",
    "### Train on the upsampled dataset\n",
    "X = np.array(data_upsampled[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data_upsampled['balance'])\n",
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "### Test on unbalanced test dataset\n",
    "X = np.array(data[['x1', 'x2', 'x3', 'x4']])\n",
    "y = np.array(data['balance'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 42, stratify = y)\n",
    "\n",
    "#### Random forest\n",
    "model_name = \"RandomForest\"\n",
    "clf_rf = ensemble.RandomForestClassifier(n_estimators = 100)\n",
    "clf_rf  = clf_rf .fit(X_train_up, y_train_up)\n",
    "# Evaluate the model\n",
    "y_pred = clf_rf .predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"{} - Accuracy score: {}\".format(model_name,\\\n",
    "                            accuracy))\n",
    "print(\"Recall: {}, Precision: {}, F1 score: {}\\n\".format(recall, precision, f1))\n",
    "prob_y_train_pred = clf_rf.predict_proba(X_train_up)[:, 1] \n",
    "prob_y_test_pred = clf_rf.predict_proba(X_test)[:, 1]\n",
    "print(\"AUROC val on train data\", roc_auc_score(y_train_up,prob_y_train_pred )) \n",
    "print(\"AUROC val on test data\", roc_auc_score(y_test, prob_y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Recall in test set = 1: Identify all the positive cases.\n",
    "=> Low precision: high false positive rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_analysis] *",
   "language": "python",
   "name": "conda-env-data_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
