{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING - VALIDATION\n",
    "\n",
    "**CONTENTS**\n",
    "\n",
    "- [Train Test Split](#train_test_split)\n",
    "- [k-fold Validation](#validation)\n",
    "- [Evaluation Metrics](#evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train_test_split'></a>\n",
    "\n",
    "## 1. TRAINING AND TESTING SPLIT\n",
    "\n",
    "- Split data into train and test set, shuffle = True (default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CASE STUDY EXAMPLE:**\n",
    "\n",
    "- A part of the [The BNP Paribas Cardif Claims Management dataset](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 133)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((35000, 112), (15000, 112))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load the data\n",
    "data = pd.read_csv(\"data/paribas_claims.csv\", nrows = 50000)\n",
    "print(data.shape)\n",
    "data.head(3)\n",
    "#### Select the numeric variables only\n",
    "numerics = ['int16','int32','int64','float16','float32','float64']\n",
    "numerical_vars = list(data.select_dtypes(include = numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape\n",
    "\n",
    "### Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                data.drop(labels=['target', 'ID'], axis=1),\n",
    "                data['target'], test_size=0.3, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. FOR CLASS IMBALANCE\n",
    "\n",
    "- When the data have imbalanced numbers of data points in the outcome classes (e.g. one is rare compared to the others) => change the `stratify` parameter => which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:,:2]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "                                        test_size = .2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 1, 0, 1, 0, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2,\n",
       "       1, 2, 2, 2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validation'></a>\n",
    "\n",
    "## 2. K-FOLD CROSS VALIDATION\n",
    "\n",
    "- **PROCESSS:**\n",
    "\n",
    "    + Split data into k sets.\n",
    "    + Performing k experiment runs. In each run: pick a set as test set, the rest as train set. \n",
    "    + Evaluation: Average result from these k experiments.\n",
    "=> More accurate evaluation by using all the data.\n",
    "\n",
    "- **DRAWBACK:**\n",
    "    + More compute time\n",
    "    - Train/test split minimize the training time, while K-fold CV maximize accuracy.\n",
    "    \n",
    "- k-fold is usually used in combining with grid_search.GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='evaluation_metrics'></a>\n",
    "## 3. EVALUATION METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. SIMPLE METRIC: ACCURACY\n",
    "\n",
    "- accuracy = data points with corrected labels/all data points\n",
    "- used for classification problems.\n",
    "- **Drawbacks**:\n",
    "    + not ideal for skewed classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the prediction 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2 ways to calculate the accuracy score\n",
    "# sklearn metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel = \"linear\", gamma = \"auto\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy score of the prediction\", accuracy_score(y_test, y_pred))\n",
    "# model attribute\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. CONFUSION MATRIX\n",
    "\n",
    "- Precision and recall can help illuminate the performance better for the dataset that has imbalanced classes.\n",
    "- Precision = TP/(TP + FP): Possibility to be correct among the ones identify as the target. It is also known as the positive predictive value.\n",
    "- Recall = TP/(TP + FN): The possibility to correctly identify the target among the ground truth. It is also known as sensitivity.\n",
    "- F1 score = 2 * (Precision * Recall) /(Precision + Recall)\n",
    "    + max F1: 1 => perfect precision and recall\n",
    "    + min F1: 0: either precision or recall is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples to understand the precision and recall:\n",
    "\n",
    "- **My identifier doesn't have great precision, but it does have good recall**. That means that, nearly everytime a person of interest (POI) shows up in my test set, I am able to identify the POI. The cost for this is that sometimes I get some false positives, where non-POIs get flagged.\n",
    "\n",
    "- **My identifier doesn't have great recall, but it does have good precision**. That means that, whenever a POI get flagged in my test set, I know with a lot of confidence that its very likely to be a real POI and not a false alarm. ON the other hand, the price I pay for this is that sometimes I miss real POIs, since I'm effectively reluctant to pull the trigger on edge cases.\n",
    "\n",
    "- **My identifier has a really great F1 score**. This is the best of both worlds. Both my false positive and false negative rates are low, which means that I can identify POI's reliably and accurately. If my identifier finds a POI then the person is almost certainly a POI, and if the identifier does not flag someone, then they are almost certainly not a POI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.7, 0.7])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "### Different values for `average` parameter\n",
    "# the scores for each class are returned\n",
    "recall_score(y_test, y_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999999"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate metrics for each label, and find their unweighted mean.\n",
    "recall_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.7, 0.7])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, y_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999999"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Example of binary classification\n",
    "predictions = [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n",
    "true_labels =  [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]\n",
    "precision_score(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            predicted\n",
    "             0     1\n",
    "real    0    9    3\n",
    "        1    2    6   \n",
    "    \n",
    "precision = 6/(6 + 3) = 0.6666666666666666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_analysis] *",
   "language": "python",
   "name": "conda-env-data_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
